{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Let's start our notebook with typical and Important Imports\n",
    "import os\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import python_speech_features as pySpeech \n",
    "### You might have to $ pip install python_speech_features\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MFCC fuction : The Mel Frequency Cepstral Coefficient\n",
    "## Plz refer :: http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "def get_MFCC(sr,audio):\n",
    "    features = pySpeech.mfcc(audio,sr, 0.025, 0.01, 13,appendEnergy = False)\n",
    "    features = preprocessing.scale(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here load the already separated Male and female voice \n",
    "### this serve as analogous to labelled data \n",
    "with open(\"maleaudios\") as rf:\n",
    "    filesM = [i.strip() for i in rf.readlines()]\n",
    "\n",
    "with open(\"femaleaudios\") as rf:\n",
    "    filesF = [i.strip() for i in rf.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresM = np.asarray(())\n",
    "featuresF = np.asarray(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Female Voice specific Feature engineering \n",
    "for f in filesF[:10000]:\n",
    "    try:\n",
    "        sr,audio  = read(m)\n",
    "        vectorF   = get_MFCC(sr,audio)\n",
    "        if featuresF.size == 0:\n",
    "            featuresF = vectorF\n",
    "        else:\n",
    "            featuresF = np.vstack((featuresF, vectorF))\n",
    "    except Exception as e:\n",
    "        print(\"Exception in file {}\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Male Voice specific Feature engineering \n",
    "for m in filesM[:10000]:\n",
    "    try:\n",
    "        sr,audio  = read(m)\n",
    "        vectorM   = get_MFCC(sr,audio)\n",
    "        if featuresM.size == 0:\n",
    "            featuresM = vectorM\n",
    "        else:\n",
    "            featuresM = np.vstack((featuresM, vectorM))\n",
    "    except Exception as e:\n",
    "        print(\"Exception in file {}\".format(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMMs models :: Separate Models for male and Female\n",
    "female_model = GaussianMixture(n_components = 11, max_iter = 350, covariance_type='diag', n_init = 5)\n",
    "male_model = GaussianMixture(n_components = 11, max_iter = 350, covariance_type='diag', n_init = 5)\n",
    "female_model.fit(featuresF)\n",
    "male_model.fit(featuresM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training is done by now :: Jar up the Pickle\n",
    "cPickle.dump(female_model,open(\"female.gmm\",'wb'))\n",
    "cPickle.dump(male_model,open(\"male.gmm\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
